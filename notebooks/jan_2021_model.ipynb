{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# coding=utf-8\r\n",
    "# Copyright 2021 DAF Trucks NV.\r\n",
    "#\r\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
    "# you may not use this file except in compliance with the License.\r\n",
    "# You may obtain a copy of the License at\r\n",
    "#\r\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\r\n",
    "#\r\n",
    "# Unless required by applicable law or agreed to in writing, software\r\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
    "# See the License for the specific language governing permissions and\r\n",
    "# limitations under the License.\r\n",
    "\r\n",
    "# Lint as: python3\r\n",
    "\"\"\"Trains TFT based on a defined set of parameters.\r\n",
    "\r\n",
    "Uses default parameters supplied from the configs file to train a TFT model from\r\n",
    "scratch.\r\n",
    "\r\n",
    "Usage:\r\n",
    "python3 script_train_fixed_params {expt_name} {output_folder}\r\n",
    "\r\n",
    "Command line args:\r\n",
    "  expt_name: Name of dataset/experiment to train.\r\n",
    "  output_folder: Root folder in which experiment is saved\r\n",
    "\r\n",
    "\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "import argparse\r\n",
    "import datetime as dte\r\n",
    "import os\r\n",
    "\r\n",
    "import data_formatters.base\r\n",
    "import expt_settings.configs\r\n",
    "import libs.hyperparam_opt\r\n",
    "import libs.tft_model_2\r\n",
    "import libs.utils as utils\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import tensorflow as tf\r\n",
    "import data_formatters.daf_extended\r\n",
    "\r\n",
    "ExperimentConfig = expt_settings.configs.ExperimentConfig\r\n",
    "HyperparamOptManager = libs.hyperparam_opt.HyperparamOptManager\r\n",
    "ModelClass = libs.tft_model_2.TemporalFusionTransformer\r\n",
    "DafFormatter = data_formatters.daf_extended.DafExtendedFormatter()\r\n",
    "\r\n",
    "\r\n",
    "def main(expt_name,\r\n",
    "         model_folder,\r\n",
    "         data_csv_path,\r\n",
    "         data_formatter,\r\n",
    "         use_testing_mode=False):\r\n",
    "  \"\"\"Trains tft based on defined model params.\r\n",
    "\r\n",
    "  Args:\r\n",
    "    expt_name: Name of experiment\r\n",
    "    model_folder: Folder path where models are serialized\r\n",
    "    data_csv_path: Path to csv file containing data\r\n",
    "    data_formatter: Dataset-specific data fromatter (see\r\n",
    "      expt_settings.dataformatter.GenericDataFormatter)\r\n",
    "    use_testing_mode: Uses a smaller models and data sizes for testing purposes\r\n",
    "      only -- switch to False to use original default settings\r\n",
    "  \"\"\"\r\n",
    "\r\n",
    "  num_repeats = 1\r\n",
    "\r\n",
    "  if not isinstance(data_formatter, data_formatters.base.GenericDataFormatter):\r\n",
    "    raise ValueError(\r\n",
    "        \"Data formatters should inherit from\" +\r\n",
    "        \"AbstractDataFormatter! Type={}\".format(type(data_formatter)))\r\n",
    "\r\n",
    "  # Tensorflow setup\r\n",
    "  # default_keras_session = tf.keras.backend.get_session()\r\n",
    "\r\n",
    "  # if use_gpu:\r\n",
    "  #   tf_config = utils.get_default_tensorflow_config(tf_device=\"gpu\", gpu_id=0)\r\n",
    "\r\n",
    "  # else:\r\n",
    "  #   tf_config = utils.get_default_tensorflow_config(tf_device=\"cpu\")\r\n",
    "\r\n",
    "  print(\"*** Training from defined parameters for {} ***\".format(expt_name))\r\n",
    "\r\n",
    "  print(\"Loading & splitting data...\")\r\n",
    "  raw_data = pd.read_csv(data_csv_path, index_col=0)\r\n",
    "  train, valid, test = data_formatter.split_data(raw_data)\r\n",
    "  train_samples, valid_samples = data_formatter.get_num_samples_for_calibration(\r\n",
    "  )\r\n",
    "\r\n",
    "  # Sets up default params\r\n",
    "  fixed_params = data_formatter.get_experiment_params()\r\n",
    "  params = data_formatter.get_default_model_params()\r\n",
    "  params[\"model_folder\"] = model_folder\r\n",
    "\r\n",
    "  # Parameter overrides for testing only! Small sizes used to speed up script.\r\n",
    "  if use_testing_mode:\r\n",
    "    fixed_params[\"num_epochs\"] = 1\r\n",
    "    params[\"hidden_layer_size\"] = 5\r\n",
    "    train_samples, valid_samples = 100, 10\r\n",
    "\r\n",
    "  # Sets up hyperparam manager\r\n",
    "  print(\"*** Loading hyperparm manager ***\")\r\n",
    "  opt_manager = HyperparamOptManager({k: [params[k]] for k in params},\r\n",
    "                                     fixed_params, model_folder)\r\n",
    "\r\n",
    "  # Training -- one iteration only\r\n",
    "  print(\"*** Running calibration ***\")\r\n",
    "  print(\"Params Selected:\")\r\n",
    "  for k in params:\r\n",
    "    print(\"{}: {}\".format(k, params[k]))\r\n",
    "\r\n",
    "  best_loss = np.Inf\r\n",
    "  for _ in range(num_repeats):\r\n",
    "\r\n",
    "    # tf.reset_default_graph()\r\n",
    "    # with tf.Graph().as_default(), tf.Session(config=tf_config) as sess:\r\n",
    "\r\n",
    "      # tf.keras.backend.set_session(sess)\r\n",
    "\r\n",
    "      params = opt_manager.get_next_parameters()\r\n",
    "      model = ModelClass(params)\r\n",
    "\r\n",
    "      if not model.training_data_cached():\r\n",
    "        model.cache_batched_data(train, \"train\", num_samples=train_samples)\r\n",
    "        model.cache_batched_data(valid, \"valid\", num_samples=valid_samples)\r\n",
    "\r\n",
    "      # sess.run(tf.global_variables_initializer())\r\n",
    "      model.fit()\r\n",
    "\r\n",
    "      val_loss = model.evaluate()\r\n",
    "\r\n",
    "      if val_loss < best_loss:\r\n",
    "        opt_manager.update_score(params, val_loss, model)\r\n",
    "        best_loss = val_loss\r\n",
    "\r\n",
    "      # tf.keras.backend.set_session(default_keras_session)\r\n",
    "\r\n",
    "  print(\"*** Running tests ***\")\r\n",
    "  # tf.reset_default_graph()\r\n",
    "  # with tf.Graph().as_default(), tf.Session(config=tf_config) as sess:\r\n",
    "    # tf.keras.backend.set_session(sess)\r\n",
    "  best_params = opt_manager.get_best_params()\r\n",
    "  model = ModelClass(best_params)\r\n",
    "\r\n",
    "  model.load(opt_manager.hyperparam_folder)\r\n",
    "\r\n",
    "  print(\"Computing best validation loss\")\r\n",
    "  val_loss = model.evaluate(valid)\r\n",
    "\r\n",
    "  print(\"Computing test loss\")\r\n",
    "  output_map = model.predict(test, return_targets=True)\r\n",
    "  targets = data_formatter.format_predictions(output_map[\"targets\"])\r\n",
    "  p50_forecast = data_formatter.format_predictions(output_map[\"p50\"])\r\n",
    "  p90_forecast = data_formatter.format_predictions(output_map[\"p90\"])\r\n",
    "\r\n",
    "  def extract_numerical_data(data):\r\n",
    "    \"\"\"Strips out forecast time and identifier columns.\"\"\"\r\n",
    "    return data[[\r\n",
    "        col for col in data.columns\r\n",
    "        if col not in {\"forecast_time\", \"identifier\"}\r\n",
    "    ]]\r\n",
    "\r\n",
    "  p50_loss = utils.numpy_normalised_quantile_loss(\r\n",
    "      extract_numerical_data(targets), extract_numerical_data(p50_forecast),\r\n",
    "      0.5)\r\n",
    "  p90_loss = utils.numpy_normalised_quantile_loss(\r\n",
    "      extract_numerical_data(targets), extract_numerical_data(p90_forecast),\r\n",
    "      0.9)\r\n",
    "\r\n",
    "    # tf.keras.backend.set_session(default_keras_session)\r\n",
    "\r\n",
    "  print(\"Training completed @ {}\".format(dte.datetime.now()))\r\n",
    "  print(\"Best validation loss = {}\".format(val_loss))\r\n",
    "  print(\"Params:\")\r\n",
    "\r\n",
    "  for k in best_params:\r\n",
    "    print(k, \" = \", best_params[k])\r\n",
    "  print()\r\n",
    "  print(\"Normalised Quantile Loss for Test Data: P50={}, P90={}\".format(\r\n",
    "      p50_loss.mean(), p90_loss.mean()))\r\n",
    "\r\n",
    "  return output_map\r\n",
    "\r\n",
    "\r\n",
    "model = main(\r\n",
    "      expt_name='daf',\r\n",
    "      model_folder='tft_outputs/saved_models/daf/fixed',\r\n",
    "      data_csv_path='tft_outputs/data/daf/tf_input.csv',\r\n",
    "      data_formatter=DafFormatter,\r\n",
    "      use_testing_mode=False)  # Change to false to use original default params\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.5.0\n",
      "*** Training from defined parameters for daf ***\n",
      "Loading & splitting data...\n",
      "Processed 0 out of 68 drivers\n",
      "Setting scalers with training data...\n",
      "*** Loading hyperparm manager ***\n",
      "*** Running calibration ***\n",
      "Params Selected:\n",
      "dropout_rate: 0.2\n",
      "hidden_layer_size: 20\n",
      "learning_rate: 0.001\n",
      "minibatch_size: 64\n",
      "max_gradient_norm: 1.0\n",
      "num_heads: 4\n",
      "stack_size: 1\n",
      "model_folder: tft_outputs/saved_models/daf/fixed\n",
      "Resetting temp folder\n",
      "Cached data \"train\" updated\n",
      "Cached data \"valid\" updated\n",
      "*** Fitting TemporalFusionTransformer ***\n",
      "Getting batched_data\n",
      "Using cached training data\n",
      "Using cached validation data\n",
      "Using keras standard fit\n",
      "Epoch 1/100\n",
      "109/109 [==============================] - 49s 172ms/step - loss: 0.5885 - root_mean_squared_error: 1.1745 - mean_absolute_error: 0.9075 - val_loss: 0.3720 - val_root_mean_squared_error: 0.8213 - val_mean_absolute_error: 0.6720\n",
      "Epoch 2/100\n",
      "109/109 [==============================] - 15s 138ms/step - loss: 0.3736 - root_mean_squared_error: 0.7395 - mean_absolute_error: 0.5928 - val_loss: 0.3297 - val_root_mean_squared_error: 0.6828 - val_mean_absolute_error: 0.5530\n",
      "Epoch 3/100\n",
      "109/109 [==============================] - 15s 137ms/step - loss: 0.3453 - root_mean_squared_error: 0.6755 - mean_absolute_error: 0.5425 - val_loss: 0.3226 - val_root_mean_squared_error: 0.6549 - val_mean_absolute_error: 0.5246\n",
      "Epoch 4/100\n",
      "109/109 [==============================] - 15s 137ms/step - loss: 0.3369 - root_mean_squared_error: 0.6611 - mean_absolute_error: 0.5275 - val_loss: 0.3172 - val_root_mean_squared_error: 0.6664 - val_mean_absolute_error: 0.5339\n",
      "Epoch 5/100\n",
      "109/109 [==============================] - 15s 137ms/step - loss: 0.3314 - root_mean_squared_error: 0.6480 - mean_absolute_error: 0.5152 - val_loss: 0.3132 - val_root_mean_squared_error: 0.6489 - val_mean_absolute_error: 0.5187\n",
      "Epoch 6/100\n",
      "109/109 [==============================] - 15s 135ms/step - loss: 0.3274 - root_mean_squared_error: 0.6409 - mean_absolute_error: 0.5083 - val_loss: 0.3125 - val_root_mean_squared_error: 0.6124 - val_mean_absolute_error: 0.4822\n",
      "Epoch 7/100\n",
      "109/109 [==============================] - 15s 134ms/step - loss: 0.3242 - root_mean_squared_error: 0.6339 - mean_absolute_error: 0.5032 - val_loss: 0.3111 - val_root_mean_squared_error: 0.6213 - val_mean_absolute_error: 0.4925\n",
      "Epoch 8/100\n",
      "109/109 [==============================] - 15s 134ms/step - loss: 0.3208 - root_mean_squared_error: 0.6362 - mean_absolute_error: 0.5026 - val_loss: 0.3107 - val_root_mean_squared_error: 0.6314 - val_mean_absolute_error: 0.5007\n",
      "Epoch 9/100\n",
      "109/109 [==============================] - 15s 134ms/step - loss: 0.3190 - root_mean_squared_error: 0.6292 - mean_absolute_error: 0.4961 - val_loss: 0.3171 - val_root_mean_squared_error: 0.6820 - val_mean_absolute_error: 0.5489\n",
      "Epoch 10/100\n",
      "109/109 [==============================] - 15s 134ms/step - loss: 0.3166 - root_mean_squared_error: 0.6289 - mean_absolute_error: 0.4974 - val_loss: 0.3125 - val_root_mean_squared_error: 0.5938 - val_mean_absolute_error: 0.4677\n",
      "Epoch 11/100\n",
      "109/109 [==============================] - 15s 134ms/step - loss: 0.3155 - root_mean_squared_error: 0.6199 - mean_absolute_error: 0.4901 - val_loss: 0.3087 - val_root_mean_squared_error: 0.6436 - val_mean_absolute_error: 0.5104\n",
      "Epoch 12/100\n",
      "109/109 [==============================] - 15s 134ms/step - loss: 0.3123 - root_mean_squared_error: 0.6204 - mean_absolute_error: 0.4888 - val_loss: 0.3112 - val_root_mean_squared_error: 0.6270 - val_mean_absolute_error: 0.4963\n",
      "Epoch 13/100\n",
      "109/109 [==============================] - 15s 134ms/step - loss: 0.3092 - root_mean_squared_error: 0.6173 - mean_absolute_error: 0.4859 - val_loss: 0.3060 - val_root_mean_squared_error: 0.6135 - val_mean_absolute_error: 0.4854\n",
      "Epoch 14/100\n",
      "109/109 [==============================] - 15s 134ms/step - loss: 0.3088 - root_mean_squared_error: 0.6140 - mean_absolute_error: 0.4844 - val_loss: 0.3070 - val_root_mean_squared_error: 0.5715 - val_mean_absolute_error: 0.4470\n",
      "Epoch 15/100\n",
      "109/109 [==============================] - 15s 134ms/step - loss: 0.3089 - root_mean_squared_error: 0.6081 - mean_absolute_error: 0.4800 - val_loss: 0.3137 - val_root_mean_squared_error: 0.5821 - val_mean_absolute_error: 0.4554\n",
      "Epoch 16/100\n",
      "109/109 [==============================] - 15s 134ms/step - loss: 0.3066 - root_mean_squared_error: 0.6062 - mean_absolute_error: 0.4778 - val_loss: 0.3072 - val_root_mean_squared_error: 0.6224 - val_mean_absolute_error: 0.4924\n",
      "Epoch 17/100\n",
      "109/109 [==============================] - 15s 136ms/step - loss: 0.3069 - root_mean_squared_error: 0.6075 - mean_absolute_error: 0.4788 - val_loss: 0.3099 - val_root_mean_squared_error: 0.6288 - val_mean_absolute_error: 0.4992\n",
      "Epoch 18/100\n",
      "109/109 [==============================] - 15s 135ms/step - loss: 0.3048 - root_mean_squared_error: 0.6047 - mean_absolute_error: 0.4760 - val_loss: 0.3118 - val_root_mean_squared_error: 0.6056 - val_mean_absolute_error: 0.4747\n",
      "Cannot load from tft_outputs/saved_models/daf/fixed\\tmp, skipping ...\n",
      "Using cached validation data\n",
      "40/40 [==============================] - 1s 26ms/step - loss: 0.3118 - root_mean_squared_error: 0.6057 - mean_absolute_error: 0.4748\n",
      "Optimal model found, updating\n",
      "Model saved to: tft_outputs/saved_models/daf/fixed\\TemporalFusionTransformer.ckpt\n",
      "*** Running tests ***\n",
      "Resetting temp folder\n",
      "Loading model from tft_outputs/saved_models/daf/fixed\\TemporalFusionTransformer.ckpt\n",
      "Computing best validation loss\n",
      "40/40 [==============================] - 6s 26ms/step - loss: 0.3118 - root_mean_squared_error: 0.6057 - mean_absolute_error: 0.4748\n",
      "Computing test loss\n",
      "Training completed @ 2021-07-26 13:25:50.300443\n",
      "Best validation loss = 0.3118060529232025\n",
      "Params:\n",
      "dropout_rate  =  0.2\n",
      "hidden_layer_size  =  20\n",
      "learning_rate  =  0.001\n",
      "max_gradient_norm  =  1.0\n",
      "minibatch_size  =  64\n",
      "model_folder  =  tft_outputs/saved_models/daf/fixed\n",
      "num_heads  =  4\n",
      "stack_size  =  1\n",
      "total_time_steps  =  15\n",
      "num_encoder_steps  =  14\n",
      "num_epochs  =  100\n",
      "early_stopping_patience  =  5\n",
      "multiprocessing_workers  =  5\n",
      "column_definition  =  [('DRIVERID', <DataTypes.CATEGORICAL: 1>, <InputTypes.ID: 4>), ('END_DATETIME', <DataTypes.DATE: 2>, <InputTypes.TIME: 5>), ('GROSS_WEIGHT', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('TRIP_DISTANCE', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('ALTITUDE_DELTA', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('USED_FUEL', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('FUEL_CONSUMPTION', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('CC_DIST', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('CC_ENABLED', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('BRAKEDURATION', <DataTypes.REAL_VALUED: 0>, <InputTypes.OBSERVED_INPUT: 1>), ('DPA_SCORE', <DataTypes.REAL_VALUED: 0>, <InputTypes.TARGET: 0>), ('TIME_STEPS', <DataTypes.REAL_VALUED: 0>, <InputTypes.KNOWN_INPUT: 2>), ('TRUCK_TYPE', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>), ('AXLE_CONF', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>), ('COMMERCIAL_NAME', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>), ('TRUCK_SERIES', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>), ('TRUCK_ENGINE', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>), ('CATEGORICAL_ID', <DataTypes.CATEGORICAL: 1>, <InputTypes.STATIC_INPUT: 3>), ('DAYOFWEEK', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>), ('HOUROFDAY', <DataTypes.CATEGORICAL: 1>, <InputTypes.OBSERVED_INPUT: 1>)]\n",
      "input_size  =  18\n",
      "output_size  =  1\n",
      "category_counts  =  [2, 3, 5, 3, 3, 68, 7, 24]\n",
      "input_obs_loc  =  [8]\n",
      "static_input_loc  =  [15]\n",
      "known_regular_inputs  =  [9]\n",
      "known_categorical_inputs  =  [5]\n",
      "\n",
      "Normalised Quantile Loss for Test Data: P50=0.10075643034379891, P90=0.04761837295695178\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "targets = list(model['targets']['t+0'].values)\r\n",
    "p50 = list(model['p50']['t+0'].values)\r\n",
    "p90 = list(model['p90']['t+0'].values)\r\n",
    "p10 = list(model['p10']['t+0'].values)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "target_unscaled = DafFormatter._target_scaler.inverse_transform(targets)\r\n",
    "p50_unscaled = DafFormatter._target_scaler.inverse_transform(p50)\r\n",
    "p90_unscaled = DafFormatter._target_scaler.inverse_transform(p90)\r\n",
    "p10_unscaled = DafFormatter._target_scaler.inverse_transform(p10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\r\n",
    "\r\n",
    "print('RMSE p10: {}'.format(mean_squared_error(targets, p10, squared=False)))\r\n",
    "print('MAE p10: {}'.format(mean_absolute_error(targets, p10)))\r\n",
    "print('RMSE p50: {}'.format(mean_squared_error(targets, p50, squared=False)))\r\n",
    "print('MAE p50: {}'.format(mean_absolute_error(targets, p50)))\r\n",
    "print('RMSE p90: {}'.format(mean_squared_error(targets, p90, squared=False)))\r\n",
    "print('MAE p90: {}'.format(mean_absolute_error(targets, p90)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE p10: 0.657558198616771\n",
      "MAE p10: 0.5417359999119177\n",
      "RMSE p50: 0.37721609688677055\n",
      "MAE p50: 0.29537890394080946\n",
      "RMSE p90: 0.6457505180028803\n",
      "MAE p90: 0.5418440704028481\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\r\n",
    "\r\n",
    "print('RMSE p10 unscaled: {}'.format(mean_squared_error(target_unscaled, p10_unscaled, squared=False)))\r\n",
    "print('MAE p10 unscaled: {}'.format(mean_absolute_error(target_unscaled, p10_unscaled)))\r\n",
    "print('RMSE p50 unscaled: {}'.format(mean_squared_error(target_unscaled, p50_unscaled, squared=False)))\r\n",
    "print('MAE p50 unscaled: {}'.format(mean_absolute_error(target_unscaled, p50_unscaled)))\r\n",
    "print('RMSE p90 unscaled: {}'.format(mean_squared_error(target_unscaled, p90_unscaled, squared=False)))\r\n",
    "print('MAE p90 unscaled: {}'.format(mean_absolute_error(target_unscaled, p90_unscaled)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RMSE p10 unscaled: 12.39535243238878\n",
      "MAE p10 unscaled: 10.21203674979832\n",
      "RMSE p50 unscaled: 7.110741483877969\n",
      "MAE p50 unscaled: 5.568063183660092\n",
      "RMSE p90 unscaled: 12.172771394464608\n",
      "MAE p90 unscaled: 10.214074669989985\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "5f23c331dcc0e959a18d97d72b32723b8e8fefc4a029dc171226f15b89161c30"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}